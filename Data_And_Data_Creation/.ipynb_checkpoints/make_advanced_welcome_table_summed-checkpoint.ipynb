{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Makes advanced_welcome_table_summed from Welcome_Table_All_Dates_All_Data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import unicodecsv\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def read_csv(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        reader = unicodecsv.DictReader(f)\n",
    "        return list(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "csv_list = []\n",
    "welcome_table_june = read_csv('Welcome_Table_All_Dates_All_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#welcome_table_june"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_to_int(column_name):\n",
    "    for row in welcome_table_june:\n",
    "        if row[column_name].strip() == \"\":\n",
    "            row[column_name] = 0\n",
    "        row[column_name] = int(row[column_name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set_to_int('# Returns')\n",
    "set_to_int('# New')\n",
    "set_to_int('# in Group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_date(date):\n",
    "    if date == '':\n",
    "        return None\n",
    "    else:\n",
    "        try:\n",
    "            return dt.strptime(date, '%m/%d/%Y')\n",
    "        except:\n",
    "            return dt.strptime(date, '%m/%d/%y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for row in welcome_table_june:\n",
    "    try:\n",
    "        if len(row['Date']) > 4:\n",
    "            new_date = row['Date']\n",
    "        row['Date'] = parse_date(new_date)\n",
    "    except:\n",
    "        print row['Date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouping the data by date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "welcome_table_stats_by_date = defaultdict(list)\n",
    "for row in welcome_table_june:\n",
    "    welcome_table_stats_by_date[str(row[\"Date\"]).split(' ',1)[0]].append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropping {u'# in Group': 17, u'Temperature': u'', u'Zip code': u'', u'Weather': u'', u'# Returns': 17, u'Date': datetime.datetime(2016, 12, 1, 0, 0), u'# New': 0}\n",
      "dropping {u'# in Group': 4, u'Temperature': u'42', u'Zip code': u'', u'Weather': u'windy', u'# Returns': 0, u'Date': datetime.datetime(2017, 3, 2, 0, 0), u'# New': 4}\n",
      "dropping {u'# in Group': 2, u'Temperature': u'49', u'Zip code': u'', u'Weather': u'Sunny/windy', u'# Returns': 0, u'Date': datetime.datetime(2016, 11, 12, 0, 0), u'# New': 2}\n",
      "dropping {u'# in Group': 73, u'Temperature': u'84', u'Zip code': u'', u'Weather': u'sunny', u'# Returns': 44, u'Date': datetime.datetime(2016, 8, 27, 0, 0), u'# New': 29}\n",
      "dropping {u'# in Group': 2, u'Temperature': u'88', u'Zip code': u'', u'Weather': u'Sunny', u'# Returns': 0, u'Date': datetime.datetime(2016, 9, 10, 0, 0), u'# New': 2}\n",
      "dropping {u'# in Group': 2, u'Temperature': u'75', u'Zip code': u'', u'Weather': u'Sunny', u'# Returns': 0, u'Date': datetime.datetime(2016, 9, 17, 0, 0), u'# New': 2}\n",
      "dropping {u'# in Group': 51, u'Temperature': u'', u'Zip code': u'', u'Weather': u'', u'# Returns': 29, u'Date': datetime.datetime(2016, 12, 18, 0, 0), u'# New': 20}\n",
      "dropping {u'# in Group': 0, u'Temperature': u'60', u'Zip code': u'', u'Weather': u'sunny ', u'# Returns': 0, u'Date': datetime.datetime(2016, 11, 1, 0, 0), u'# New': 0}\n",
      "dropping {u'# in Group': 3, u'Temperature': u'', u'Zip code': u'', u'Weather': u'', u'# Returns': 0, u'Date': datetime.datetime(2016, 10, 16, 0, 0), u'# New': 3}\n",
      "dropping {u'# in Group': 0, u'Temperature': u'61', u'Zip code': u'', u'Weather': u'Cloudy', u'# Returns': 0, u'Date': datetime.datetime(2017, 2, 25, 0, 0), u'# New': 0}\n",
      "dropping {u'# in Group': 0, u'Temperature': u'44', u'Zip code': u'', u'Weather': u'Rain/thunderstorm', u'# Returns': 0, u'Date': datetime.datetime(2017, 4, 6, 0, 0), u'# New': 0}\n",
      "dropping {u'# in Group': 105, u'Temperature': u'90', u'Zip code': u'', u'Weather': u'Sunny', u'# Returns': 32, u'Date': datetime.datetime(2016, 8, 7, 0, 0), u'# New': 73}\n",
      "dropping {u'# in Group': 48, u'Temperature': u'90', u'Zip code': u'', u'Weather': u'Sunny', u'# Returns': 9, u'Date': datetime.datetime(2016, 8, 9, 0, 0), u'# New': 36}\n"
     ]
    }
   ],
   "source": [
    "summed_by_date = {}\n",
    "for key in welcome_table_stats_by_date:\n",
    "    total_visitors = 0\n",
    "    total_new = 0\n",
    "    total_returns = 0\n",
    "    weather = \"\"\n",
    "    temperature = \"\"\n",
    "    local = 0\n",
    "    fake = False\n",
    "    for visit in welcome_table_stats_by_date[key]:\n",
    "        if visit[\"Zip code\"]:\n",
    "            total_visitors += visit[\"# in Group\"]\n",
    "            total_new += visit[\"# New\"]\n",
    "            total_returns += visit[\"# Returns\"]\n",
    "        else:\n",
    "            #fake = True\n",
    "            print \"dropping\", visit\n",
    "        if(visit[\"Zip code\"] == \"11201\"):\n",
    "            local += visit[\"# in Group\"]\n",
    "        if (visit[\"Temperature\"]):\n",
    "            temperature = visit[\"Temperature\"]\n",
    "    if total_visitors != 0 and not fake:\n",
    "        summed_by_date[key] = {\"total_visitors\": total_visitors, \"total_new\": total_new, \"total_returns\":total_returns,\"from_11201\": local, \"Temperature\": temperature}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "summed_by_date =  pd.DataFrame.from_dict(summed_by_date, orient = 'index' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding weather data and additional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# load from file:\n",
    "with open('past_weather.json', 'r') as f:\n",
    "    try:\n",
    "        weather_dict1 = json.load(f)\n",
    "    # if the file is empty the ValueError will be thrown\n",
    "    except ValueError:\n",
    "        data = {}\n",
    "        \n",
    "with open('past_weather2.json', 'r') as f:\n",
    "    try:\n",
    "        weather_dict2 = json.load(f)\n",
    "    # if the file is empty the ValueError will be thrown\n",
    "    except ValueError:\n",
    "        data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-10-03 weather\n"
     ]
    }
   ],
   "source": [
    "summed_by_date[\"avg_visits_per_hour\"] = float('nan')\n",
    "summed_by_date[\"avg_returns_per_hour\"] = float('nan')\n",
    "summed_by_date[\"avg_new_per_hour\"] = float('nan')\n",
    "summed_by_date[\"avg_from_11201_per_hour\"] = float('nan')\n",
    "summed_by_date[\"ratio_11201\"] = float('nan')\n",
    "summed_by_date[\"day\"] = \"\"\n",
    "summed_by_date['week'] = \"\"\n",
    "summed_by_date[\"month\"] = 6\n",
    "summed_by_date[\"year\"] = 2016\n",
    "summed_by_date[\"given_temp\"] = summed_by_date[\"Temperature\"]\n",
    "summed_by_date[\"precipitation\"] =  float('nan')\n",
    "summed_by_date[\"cloud_cover\"] = float('nan')\n",
    "summed_by_date[\"snow\"] = float('nan')\n",
    "summed_by_date[\"rain\"] = float('nan')\n",
    "summed_by_date.total_returns = summed_by_date.total_returns.astype(float)\n",
    "summed_by_date.total_new = summed_by_date.total_new.astype(float)\n",
    "summed_by_date.from_11201 = summed_by_date.from_11201.astype(float)\n",
    "        \n",
    "for val in summed_by_date.index.values:\n",
    "    if summed_by_date.loc[val]['total_visitors'] != 0 and summed_by_date.loc[val]['total_returns'] <1 and summed_by_date.loc[val]['total_new'] <1:\n",
    "        summed_by_date.set_value(val,'total_returns', float('nan'))\n",
    "        summed_by_date.set_value(val, 'total_new', float('nan'))\n",
    "    if val != 'None':\n",
    "        the_date = dt.strptime(val, \"%Y-%m-%d\")\n",
    "        if the_date < dt.strptime(\"2018-04-01\", \"%Y-%m-%d\"):\n",
    "            weather_dict = weather_dict1\n",
    "        else:\n",
    "            weather_dict = weather_dict2\n",
    "        if the_date < dt.strptime(\"2016-02-06\", \"%Y-%m-%d\"):\n",
    "            summed_by_date.set_value(val,'from_11201', float('nan'))\n",
    "        if the_date.weekday() >= 5:\n",
    "            hours = 4\n",
    "        elif the_date.weekday() == 1 or  the_date.weekday() == 3:\n",
    "            hours = 2\n",
    "        else:\n",
    "            hours = 2\n",
    "        try:\n",
    "            try:\n",
    "                if weather_dict[val][0]['precipIntensity'] > 0:\n",
    "                    if weather_dict[val][0]['precipType'] == 'snow':\n",
    "                        summed_by_date.set_value(val, 'snow', 1)\n",
    "                        summed_by_date.set_value(val, 'rain', 0)\n",
    "                    elif weather_dict[val][0]['precipType'] == 'rain':\n",
    "                        summed_by_date.set_value(val, 'rain', 1)\n",
    "                        summed_by_date.set_value(val, 'snow', 0)\n",
    "                    else:\n",
    "                        print weather_dict[val][0]['precipType']\n",
    "                else:\n",
    "                    summed_by_date.set_value(val, 'snow', 0)\n",
    "                    summed_by_date.set_value(val, 'rain', 0)\n",
    "                    \n",
    "                summed_by_date.set_value(val, 'Temperature', weather_dict[val][0][\"temperatureMax\"])\n",
    "                summed_by_date.set_value(val, 'precipitation', weather_dict[val][0]['precipIntensity'])\n",
    "                summed_by_date.set_value(val, 'cloud_cover', weather_dict[val][0]['cloudCover'])\n",
    "            except:\n",
    "                print val, \"weather\"\n",
    "            summed_by_date.set_value(val, \"day\", the_date.weekday())\n",
    "            summed_by_date.set_value(val, \"week\", the_date.isocalendar()[1])\n",
    "            summed_by_date.set_value(val, \"month\", the_date.month)\n",
    "            summed_by_date.set_value(val, \"year\", the_date.year)\n",
    "            summed_by_date.set_value(val, \"ratio_11201\", summed_by_date.loc[val][\"from_11201\"]/(1.0* summed_by_date.loc[val][\"total_visitors\"]))\n",
    "            summed_by_date.set_value(val, \"avg_visits_per_hour\", summed_by_date.loc[val][\"total_visitors\"]/(1.0*hours))\n",
    "            summed_by_date.set_value(val, \"avg_returns_per_hour\", summed_by_date.loc[val][\"total_returns\"]/(1.0*hours))\n",
    "            summed_by_date.set_value(val, \"avg_new_per_hour\", summed_by_date.loc[val][\"total_new\"]/(1.0*hours))\n",
    "            summed_by_date.set_value(val, \"avg_from_11201_per_hour\", summed_by_date.loc[val][\"from_11201\"]/(1.0*hours))\n",
    "        except:\n",
    "            print val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summed_by_date.to_csv('advanced_welcome_table_summed.csv', sep =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
